{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGLDpqfXdUiF"
   },
   "source": [
    "report： https://typst.app/project/wCnTjkIeLvgrcBJBBhyQfG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9t_aJb4utVzG"
   },
   "source": [
    "## **Importing Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torchsummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 25983,
     "status": "ok",
     "timestamp": 1635353302183,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "mrnHynbttJRX"
   },
   "outputs": [],
   "source": [
    "#importing required modules\n",
    "\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Qe2Ay1Ntj0b"
   },
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done splitting and organizing images into split/train, split/val, split/test.\n"
     ]
    }
   ],
   "source": [
    "#file split \n",
    "\n",
    "# split it into 70:15:15\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Split into train/val/test\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['has_cactus'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['has_cactus'], random_state=42)\n",
    "\n",
    "splits = {\n",
    "    'train': train_df,\n",
    "    'valid': val_df,\n",
    "    'test': test_df\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "for split in splits:\n",
    "    for label in [0, 1]:\n",
    "        os.makedirs(f'split/{split}/{label}', exist_ok=True)\n",
    "\n",
    "# Copy files\n",
    "for split_name, split_df in splits.items():\n",
    "    for _, row in split_df.iterrows():\n",
    "        label = row['has_cactus']\n",
    "        image_id = row['id']\n",
    "        src = os.path.join('train/train', image_id)\n",
    "        dst = os.path.join('split', split_name, str(label), image_id)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "print(\"✅ Done splitting and organizing images into split/train, split/val, split/test.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3471,
     "status": "ok",
     "timestamp": 1635353325164,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "x8L_TuJ6dfvn",
    "outputId": "8fdaa6eb-dfb0-45cd-bc7b-0bed1b369615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20126 total  images.\n"
     ]
    }
   ],
   "source": [
    "#importing data\n",
    "\n",
    "# #Dataset address\n",
    "# url = 'https://drive.google.com/uc?export=download&id=1B75cOYH7VCaiqdeQYvMuUuy_Mn_5tPMY'\n",
    "# output = 'data.zip'\n",
    "# # gdown.download(url, output, quiet=False)\n",
    "\n",
    "# #giving zip file name\n",
    "# data_dir='./data.zip'\n",
    "\n",
    "# #extractng data from zip file\n",
    "# with zipfile.ZipFile(data_dir, 'r') as zf:\n",
    "#     zf.extractall('./data')\n",
    "#     print('Done downloading and extraction')\n",
    "\n",
    "# #removing zip file after extraction\n",
    "# !rm './data.zip' \n",
    "\n",
    "#invstigating number of files\n",
    "cactus_files = np.array(glob(\"./split/*/*/*\"))\n",
    "print('There are %d total  images.' % len(cactus_files))\n",
    "\n",
    "#checking the availability of a GPU\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36996,
     "status": "ok",
     "timestamp": 1635353368474,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "m_ZRinCNYQFu",
    "outputId": "cd521332-ea09-4990-9635-f25b5f647a8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "tensor([0.5034, 0.4517, 0.4681])\n",
      "0\n",
      "10000\n",
      "tensor([0.1511, 0.1398, 0.1533])\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([T.ToTensor(),])\n",
    "data_file='./split/'\n",
    "\n",
    "train_path=os.path.join(data_file,'train')\n",
    "dataset = datasets.ImageFolder(train_path,transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, num_workers=1, shuffle=False)\n",
    "\n",
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "\n",
    "for i, data in enumerate(dataloader):\n",
    "    if (i % 10000 == 0): print(i)\n",
    "    data = data[0].squeeze(0)\n",
    "    if (i == 0): size = data.size(1) * data.size(2)\n",
    "    mean += data.sum((1, 2)) / size\n",
    "\n",
    "mean /= len(dataloader)\n",
    "print(mean)\n",
    "mean = mean.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "for i, data in enumerate(dataloader):\n",
    "    if (i % 10000 == 0): print(i)\n",
    "    data = data[0].squeeze(0)\n",
    "    std += ((data - mean) ** 2).sum((1, 2)) / size\n",
    "\n",
    "std /= len(dataloader)\n",
    "std = std.sqrt()\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1635353442510,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "LF2SASYAtpRP"
   },
   "outputs": [],
   "source": [
    "#declaring batch size\n",
    "batch_size = 128\n",
    "\n",
    "#applying required transformations on the dataset\n",
    "img_transforms = {\n",
    "    'train':\n",
    "    T.Compose([\n",
    "        T.Resize(size=(32,32)), \n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std), \n",
    "    ]),\n",
    "    \n",
    "\n",
    "    'valid':\n",
    "    T.Compose([\n",
    "        T.Resize(size=(32,32)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std)\n",
    "    ]),\n",
    "\n",
    "\n",
    "    'test':\n",
    "    T.Compose([\n",
    "        T.Resize(size=(32,32)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "train_path=os.path.join(data_file,'train')\n",
    "valid_path=os.path.join(data_file,'test')\n",
    "test_path=os.path.join(data_file,'valid')\n",
    "\n",
    "\n",
    "# creating datasets to each of  folder created in prev\n",
    "train_file=datasets.ImageFolder(train_path,transform=img_transforms['train'])\n",
    "valid_file=datasets.ImageFolder(valid_path,transform=img_transforms['valid'])\n",
    "test_file=datasets.ImageFolder(test_path,transform=img_transforms['test'])\n",
    "\n",
    "\n",
    "#creating loaders for the dataset\n",
    "loaders_transfer={\n",
    "    'train':torch.utils.data.DataLoader(train_file,batch_size,shuffle=True),\n",
    "    'valid':torch.utils.data.DataLoader(valid_file,batch_size,shuffle=True),\n",
    "    'test': torch.utils.data.DataLoader(test_file,batch_size,shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mu6epzLWtugF"
   },
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "b03d84ac397641b08fd28ebd8994b70f",
      "413c553d66d94709ae028a0078234f36",
      "e3f62fa4f45f4d538ba0f18a23659edd",
      "815d4ef7b6c94459b6a8bdb8db0a5cdc",
      "eaab0422842c4fe2b98fba706c48ef20",
      "b45125ae1bb547f5a862a4c5fefb3ee7",
      "74889224fb1b45e98111e20a3e2c20c0",
      "c5c8d02284ce4630b7ebdf0dd6d40380",
      "ccb46c5c9da243989ae98ef42dbd99da",
      "e19edde66758413a9545d1b96e907667",
      "9e96619265ba49799f72b73073a55289"
     ]
    },
    "executionInfo": {
     "elapsed": 19561,
     "status": "ok",
     "timestamp": 1635353481410,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "z650l_bmC4NB",
    "outputId": "f13472d1-6910-42fe-b911-841f9f51c632"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Importing the pretrained model\n",
    "model_transfer = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze weights\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "n_inputs = model_transfer.fc.in_features\n",
    "\n",
    "#Replacing the top dense layers with self defined trainable layers\n",
    "model_transfer.fc = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 1024),\n",
    "    nn.LeakyReLU(inplace = True),\n",
    "\n",
    "    nn.Linear(1024,512),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "            \n",
    "    nn.Linear(512,256),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "\n",
    "    nn.Linear(256,64),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "\n",
    "    nn.Linear(64,16),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "\n",
    "    nn.Linear(16,2),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "#transferring the model to GPU\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1086,
     "status": "ok",
     "timestamp": 1635353487795,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "jBBdkynaDIZn",
    "outputId": "23fc878a-0d82-4a76-8b6a-477fb2c10784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1024]       2,098,176\n",
      "       LeakyReLU-175                 [-1, 1024]               0\n",
      "          Linear-176                  [-1, 512]         524,800\n",
      "       LeakyReLU-177                  [-1, 512]               0\n",
      "          Linear-178                  [-1, 256]         131,328\n",
      "       LeakyReLU-179                  [-1, 256]               0\n",
      "          Linear-180                   [-1, 64]          16,448\n",
      "       LeakyReLU-181                   [-1, 64]               0\n",
      "          Linear-182                   [-1, 16]           1,040\n",
      "       LeakyReLU-183                   [-1, 16]               0\n",
      "          Linear-184                    [-1, 2]              34\n",
      "         Sigmoid-185                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 26,279,858\n",
      "Trainable params: 2,771,826\n",
      "Non-trainable params: 23,508,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.58\n",
      "Params size (MB): 100.25\n",
      "Estimated Total Size (MB): 387.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_transfer, (3, 224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1635353490928,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "Zlyln3xPfe65"
   },
   "outputs": [],
   "source": [
    "# Assuming `train_dataset` contains your training data\n",
    "class_counts = np.bincount(train_file.targets)  # Get counts per class\n",
    "class_weights = 1. / class_counts  # Inverse frequency weighting\n",
    "class_weights = class_weights / class_weights.sum()  # Normalize\n",
    "\n",
    "# Convert to tensor and move to GPU if needed\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "if use_cuda:\n",
    "    class_weights_tensor = class_weights_tensor.cuda()\n",
    "\n",
    "# Initialize weighted loss function\n",
    "criterion_transfer = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "#using Adam optimizer\n",
    "optimizer_transfer = optim.Adam(model_transfer.fc.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3055, 9195], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75061224, 0.24938776])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iLzoVz2fe65"
   },
   "source": [
    "## **Training and Validating the Model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1635353500976,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "1tknb_FNfe65"
   },
   "outputs": [],
   "source": [
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Creating the function for training\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    trainingloss = []\n",
    "    validationloss = []\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize the variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        correct1 = 0.\n",
    "        total1 = 0.\n",
    "        correct2 = 0.\n",
    "        total2 = 0.\n",
    "\n",
    "        ###################\n",
    "        # training the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "          \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "           \n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            # compare predictions\n",
    "            correct1 += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            total1 += data.size(0)\n",
    "\n",
    "       \n",
    "        ######################    \n",
    "        # validating the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            # compare predictions\n",
    "            correct2 += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            total2 += data.size(0)\n",
    "\n",
    "      \n",
    "\n",
    "        # train_loss = train_loss/len(train_file)\n",
    "        # valid_loss = valid_loss/len(valid_file)\n",
    "\n",
    "        trainingloss.append(train_loss)\n",
    "        validationloss.append(valid_loss)\n",
    "        acc1 = 100. * correct1 / total1\n",
    "        acc2 =  100. * correct2 / total2\n",
    "        # printing training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.4f} \\tValidation Loss: {:.6f} \\tValidation Accuracy: {:.4f}'.format(\n",
    "            epoch,\n",
    "            train_loss,\n",
    "            acc1,\n",
    "            valid_loss,\n",
    "            acc2\n",
    "            ))\n",
    "        \n",
    "        ## saving the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            \n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            \n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    # return trained model\n",
    "    return model, trainingloss, validationloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2182195,
     "status": "ok",
     "timestamp": 1635355687361,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "UT3eGNCPDP3Y",
    "outputId": "b22a51c0-3ef1-4688-b931-2838b4efa09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.442816 \tTraining Accuracy: 88.0898 \tValidation Loss: 0.387503 \tValidation Accuracy: 91.1238\n",
      "Validation loss decreased (inf --> 0.387503).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.389203 \tTraining Accuracy: 91.9429 \tValidation Loss: 0.378481 \tValidation Accuracy: 92.4571\n",
      "Validation loss decreased (0.387503 --> 0.378481).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.382670 \tTraining Accuracy: 92.4082 \tValidation Loss: 0.378922 \tValidation Accuracy: 92.1905\n",
      "Epoch: 4 \tTraining Loss: 0.376111 \tTraining Accuracy: 93.1429 \tValidation Loss: 0.383255 \tValidation Accuracy: 90.9714\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# training the model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[1;32m----> 5\u001b[0m model_transfer, train_loss, valid_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders_transfer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_transfer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_transfer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_transfer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_transfer.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 35\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 35\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m+\u001b[39m ((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m (loss\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m-\u001b[39m train_loss))\n\u001b[0;32m     38\u001b[0m pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32md:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32md:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torch\\optim\\adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    160\u001b[0m         group,\n\u001b[0;32m    161\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m         state_steps)\n\u001b[1;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32md:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torch\\optim\\adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torch\\optim\\adam.py:441\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "n_epochs=500\n",
    "\n",
    "model_transfer, train_loss, valid_loss = train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1635357987214,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "v26cfEnRy2F0",
    "outputId": "0d77bbce-5c62-46c4-e061-988b08016e7e"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_transfer.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_transfer\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_transfer.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torch\\serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32md:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torch\\serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32md:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torch\\serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_transfer.pt'"
     ]
    }
   ],
   "source": [
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_loss\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCDLonECfe66"
   },
   "source": [
    "##  **Testing the Model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5316,
     "status": "ok",
     "timestamp": 1635357994630,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "PgPsq4PYfe66"
   },
   "outputs": [],
   "source": [
    "# Defining the test function\n",
    "\n",
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitoring test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # moving to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # updating average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # converting the output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        preds.append(pred)\n",
    "        targets.append(target)\n",
    "        # compare predictions\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    # print('Test Loss: {:.7f}\\n'.format(test_loss))\n",
    "\n",
    "    # print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "    #     100. * correct / total, correct, total))\n",
    "    \n",
    "    return preds, targets\n",
    "\n",
    "# calling test function\n",
    "preds, targets = test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b17E9NVIvdxW"
   },
   "source": [
    "## **Visulizing the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1635358002873,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "jESeP8tj_yQg"
   },
   "outputs": [],
   "source": [
    "#converting the tensor object to a list for metric functions\n",
    "\n",
    "preds2, targets2 = [],[]\n",
    "\n",
    "for i in preds:\n",
    "  for j in range(len(i)):\n",
    "    preds2.append(1-i.cpu().numpy()[j])\n",
    "for i in targets:\n",
    "  for j in range(len(i)):\n",
    "    targets2.append(i.cpu().numpy()[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1635358009722,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "pLcFv31JwRDE",
    "outputId": "18c1581d-5e8c-4189-db4f-28a842c1e522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 556  155]\n",
      " [  98 1816]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the confusion matrix for testing data\n",
    "\n",
    "cm = confusion_matrix(preds2, targets2)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "plt.imshow(cm, cmap = plt.cm.Blues)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.title('Confusion matrix ')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 686,
     "status": "ok",
     "timestamp": 1635358015088,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "qQED5lcW_pJk",
    "outputId": "098af52c-996a-4b14-cb42-646b224a53fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score:  0.8857563105395203\n",
      "Accuracy:  0.9036190476190477\n",
      "F1 score:  0.9348777348777348\n",
      "Precision score:  0.9487983281086729\n",
      "Recall score:  0.9213597158802638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2180539faf0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Computing the 5 evaluation metrics and printing\n",
    "\n",
    "acc = accuracy_score(targets2, preds2)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(targets2, preds2)\n",
    "\n",
    "area = roc_auc_score(targets2, preds2)\n",
    "print(\"AUC score: \", area)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "f1 = f1_score(targets2, preds2)\n",
    "print(\"F1 score: \", f1)\n",
    "\n",
    "pre = precision_score(targets2, preds2)\n",
    "print(\"Precision score: \", pre)\n",
    "\n",
    "recall = recall_score(targets2, preds2)\n",
    "print(\"Recall score: \", recall)\n",
    "\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\anacoda\\envs\\Pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#load the trained model\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. Rebuild the model architecture (must match what you trained)\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "n_inputs = model.fc.in_features\n",
    "\n",
    "#Replacing the top dense layers with self defined trainable layers\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 1024),\n",
    "    nn.LeakyReLU(inplace = True),\n",
    "\n",
    "    nn.Linear(1024,512),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "            \n",
    "    nn.Linear(512,256),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "\n",
    "    nn.Linear(256,64),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "\n",
    "    nn.Linear(64,16),\n",
    "    nn.LeakyReLU(inplace=True),\n",
    "\n",
    "    nn.Linear(16,2),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Load the saved state_dict (weights only)\n",
    "model.load_state_dict(torch.load(\"model_transfer_resnet.pt\", map_location=device))\n",
    "\n",
    "# 3. Move to device and set to eval mode\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Define the same transform used during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,  # Example: use your actual mean\n",
    "                         std)   # Example: use your actual std\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prediction complete. Results saved in predict/0 and predict/1.\n"
     ]
    }
   ],
   "source": [
    "# predict in splited test dataet \n",
    "# Input folder containing raw images for prediction\n",
    "input_folder = \"split/test/unlabelled\"  # ← replace with your folder path\n",
    "output_base = \"split/test/unlabelled/predict\"\n",
    "\n",
    "# Create output folders\n",
    "for label in [\"0\", \"1\"]:\n",
    "    os.makedirs(os.path.join(output_base, label), exist_ok=True)\n",
    "\n",
    "# Loop through all images in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            predicted_class = output.argmax(dim=1).item()  # Get class index with highest score\n",
    "            label = str(1-predicted_class) # I don't know why but I have to do this to make it work\n",
    "\n",
    "        # Copy image to predicted folder\n",
    "        target_path = os.path.join(output_base, label, filename)\n",
    "        shutil.copy(image_path, target_path)\n",
    "\n",
    "print(\"✅ Prediction complete. Results saved in predict/0 and predict/1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping non-class directory: unlabelled\n",
      "Classification Accuracy: 91.31%\n",
      "✅ Comparison complete. Results saved in:\n",
      "- classification_comparison.csv\n",
      "- confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# 1. Prepare paths\n",
    "original_test_dir = \"split/test\"  # Original labeled test data\n",
    "predicted_dir = \"split/test/unlabelled/predict\"  # Your prediction results\n",
    "\n",
    "# 2. Create comparison dataframe\n",
    "def build_comparison_df(original_root, predicted_root):\n",
    "    \"\"\"Build DataFrame containing true labels and predicted labels\"\"\"\n",
    "    \n",
    "    # Initialize list to store comparison data\n",
    "    comparison = []\n",
    "    \n",
    "    # Iterate through original test directory\n",
    "    for class_dir in os.listdir(original_root):\n",
    "        if class_dir not in [\"0\", \"1\"]:  \n",
    "            print(f\"Skipping non-class directory: {class_dir}\")\n",
    "            continue\n",
    "        class_path = os.path.join(original_root, class_dir)\n",
    "        \n",
    "        if os.path.isdir(class_path):\n",
    "            true_label = class_dir  # '0' or '1'\n",
    "            \n",
    "            # Check all files in original test class\n",
    "            for img_file in os.listdir(class_path):\n",
    "                if img_file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "                    original_path = os.path.join(class_path, img_file)\n",
    "                    \n",
    "                    # Check prediction in both class folders\n",
    "                    pred_label = None\n",
    "                    for pred_class in [\"0\", \"1\"]:\n",
    "                        pred_path = os.path.join(predicted_root, pred_class, img_file)\n",
    "                        if os.path.exists(pred_path):\n",
    "                            pred_label = pred_class\n",
    "                            break\n",
    "                    \n",
    "                    comparison.append({\n",
    "                        \"filename\": img_file,\n",
    "                        \"true_label\": true_label,\n",
    "                        \"pred_label\": pred_label\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(comparison)\n",
    "\n",
    "# 3. Generate comparison dataframe\n",
    "df = build_comparison_df(original_test_dir, predicted_dir)\n",
    "\n",
    "# 4. Calculate accuracy metrics\n",
    "df[\"correct\"] = df[\"true_label\"] == df[\"pred_label\"]\n",
    "accuracy = df[\"correct\"].mean()\n",
    "\n",
    "print(f\"Classification Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# 5. Save comparison results to CSV\n",
    "df.to_csv(\"classification_comparison.csv\", index=False)\n",
    "\n",
    "# 6. Generate confusion matrix visualization\n",
    "def plot_confusion_matrix(df):\n",
    "    \"\"\"Create and save confusion matrix plot\"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(df[\"true_label\"], df[\"pred_label\"], labels=[\"0\", \"1\"])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\", \"1\"])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    disp.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "plot_confusion_matrix(df)\n",
    "\n",
    "print(\"✅ Comparison complete. Results saved in:\")\n",
    "print(\"- classification_comparison.csv\")\n",
    "print(\"- confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prediction complete. Results saved in predict/0 and predict/1.\n"
     ]
    }
   ],
   "source": [
    "#predict the pics in raw TEST dataet\n",
    "# Input folder containing raw images for prediction\n",
    "input_folder = \"test/test\"  # ← replace with your folder path\n",
    "output_base = \"predict\"\n",
    "\n",
    "# Create output folders\n",
    "for label in [\"0\", \"1\"]:\n",
    "    os.makedirs(os.path.join(output_base, label), exist_ok=True)\n",
    "\n",
    "# Loop through all images in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            predicted_class = output.argmax(dim=1).item()  # Get class index with highest score\n",
    "            label = str(1-predicted_class) # same issue, I don't know why, but I have to do it like this\n",
    "\n",
    "        # Copy image to predicted folder\n",
    "        target_path = os.path.join(output_base, label, filename)\n",
    "        shutil.copy(image_path, target_path)\n",
    "\n",
    "print(\"✅ Prediction complete. Results saved in predict/0 and predict/1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1635358019316,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "XiVePmbMJ6Hr",
    "outputId": "619fa657-b40e-4ea5-9d9b-c6881506d994"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Plotting the training loss\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_loss_cpu \u001b[38;5;241m=\u001b[39m [loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_loss\u001b[49m]\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_loss_cpu)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    }
   ],
   "source": [
    "#Plotting the training loss\n",
    "train_loss_cpu = [loss.item() for loss in train_loss]\n",
    "\n",
    "plt.plot(train_loss_cpu)\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1635358022133,
     "user": {
      "displayName": "Haris Ali",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "18402984484010107717"
     },
     "user_tz": -300
    },
    "id": "TNgyPyz3J6Hr",
    "outputId": "46222997-990f-42d7-96fd-2abf2d08797c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Plotting the validation loss\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m val_loss_cpu \u001b[38;5;241m=\u001b[39m [loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvalid_loss\u001b[49m]\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(val_loss_cpu)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'valid_loss' is not defined"
     ]
    }
   ],
   "source": [
    "#Plotting the validation loss\n",
    "val_loss_cpu = [loss.item() for loss in valid_loss]\n",
    "\n",
    "plt.plot(val_loss_cpu)\n",
    "plt.title(\"Validation loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qL95CcsJ6Hr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "yCDLonECfe66"
   ],
   "name": "ResNet50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "413c553d66d94709ae028a0078234f36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74889224fb1b45e98111e20a3e2c20c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "815d4ef7b6c94459b6a8bdb8db0a5cdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccb46c5c9da243989ae98ef42dbd99da",
      "max": 102530333,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5c8d02284ce4630b7ebdf0dd6d40380",
      "value": 102530333
     }
    },
    "9e96619265ba49799f72b73073a55289": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b03d84ac397641b08fd28ebd8994b70f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3f62fa4f45f4d538ba0f18a23659edd",
       "IPY_MODEL_815d4ef7b6c94459b6a8bdb8db0a5cdc",
       "IPY_MODEL_eaab0422842c4fe2b98fba706c48ef20"
      ],
      "layout": "IPY_MODEL_413c553d66d94709ae028a0078234f36"
     }
    },
    "b45125ae1bb547f5a862a4c5fefb3ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5c8d02284ce4630b7ebdf0dd6d40380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ccb46c5c9da243989ae98ef42dbd99da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e19edde66758413a9545d1b96e907667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3f62fa4f45f4d538ba0f18a23659edd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74889224fb1b45e98111e20a3e2c20c0",
      "placeholder": "​",
      "style": "IPY_MODEL_b45125ae1bb547f5a862a4c5fefb3ee7",
      "value": "100%"
     }
    },
    "eaab0422842c4fe2b98fba706c48ef20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e96619265ba49799f72b73073a55289",
      "placeholder": "​",
      "style": "IPY_MODEL_e19edde66758413a9545d1b96e907667",
      "value": " 97.8M/97.8M [00:03&lt;00:00, 27.0MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
